{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6e1489",
   "metadata": {},
   "source": [
    "# Quantum-Classical Hybrid Autoencoder for Medical Image Classification\n",
    "\n",
    "This notebook implements a hybrid quantum-classical model for chest X-ray classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-deps",
   "metadata": {},
   "source": [
    "## Installation (Run if packages missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "install-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.0-cp310-cp310-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (1.26.4)\n",
      "Collecting pennylane\n",
      "  Using cached pennylane-0.42.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting medmnist\n",
      "  Using cached medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Collecting scipy (from pennylane)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting rustworkx>=0.14.0 (from pennylane)\n",
      "  Using cached rustworkx-0.17.1-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting autograd (from pennylane)\n",
      "  Using cached autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting appdirs (from pennylane)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting autoray<0.8,>=0.6.11 (from pennylane)\n",
      "  Using cached autoray-0.7.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools (from pennylane)\n",
      "  Using cached cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pennylane-lightning>=0.42 (from pennylane)\n",
      "  Using cached pennylane_lightning-0.42.0-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from pennylane) (2.32.3)\n",
      "Collecting tomlkit (from pennylane)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from pennylane) (25.0)\n",
      "Collecting diastatic-malt (from pennylane)\n",
      "  Using cached diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pandas (from medmnist)\n",
      "  Using cached pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting scikit-learn (from medmnist)\n",
      "  Using cached scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scikit-image (from medmnist)\n",
      "  Using cached scikit_image-0.25.2-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from medmnist) (4.67.1)\n",
      "Collecting fire (from medmnist)\n",
      "  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.42->pennylane)\n",
      "  Using cached scipy_openblas32-0.3.30.0.6-py3-none-win_amd64.whl.metadata (56 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting astunparse (from diastatic-malt->pennylane)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting gast (from diastatic-malt->pennylane)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting termcolor (from diastatic-malt->pennylane)\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from pandas->medmnist) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->medmnist)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->medmnist)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from requests->pennylane) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from requests->pennylane) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from requests->pennylane) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from requests->pennylane) (2025.8.3)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->medmnist)\n",
      "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->medmnist)\n",
      "  Using cached tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->medmnist)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->medmnist)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->medmnist)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\siche\\appdata\\local\\pymol\\lib\\site-packages (from tqdm->medmnist) (0.4.6)\n",
      "Downloading torch-2.9.0-cp310-cp310-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.8/109.3 MB 9.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 4.2/109.3 MB 10.1 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 6.8/109.3 MB 10.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 9.4/109.3 MB 11.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 13.1/109.3 MB 12.3 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 15.5/109.3 MB 12.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 17.8/109.3 MB 12.0 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 20.2/109.3 MB 11.8 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 22.8/109.3 MB 11.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 26.2/109.3 MB 12.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 28.6/109.3 MB 12.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 30.1/109.3 MB 11.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 32.2/109.3 MB 11.6 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 34.6/109.3 MB 11.5 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 37.0/109.3 MB 11.5 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 39.1/109.3 MB 11.5 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 40.9/109.3 MB 11.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 43.8/109.3 MB 11.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 46.1/109.3 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 49.0/109.3 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 52.2/109.3 MB 11.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 54.3/109.3 MB 11.5 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 57.4/109.3 MB 11.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 60.8/109.3 MB 11.8 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 63.7/109.3 MB 11.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 65.8/109.3 MB 11.8 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 68.4/109.3 MB 11.8 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 71.0/109.3 MB 11.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 73.1/109.3 MB 11.8 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 76.0/109.3 MB 11.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 78.1/109.3 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 80.2/109.3 MB 11.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 83.6/109.3 MB 11.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 85.7/109.3 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 87.8/109.3 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 90.4/109.3 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 92.3/109.3 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 94.6/109.3 MB 11.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 96.7/109.3 MB 11.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 98.6/109.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 100.9/109.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 102.2/109.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 103.3/109.3 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 105.4/109.3 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  107.5/109.3 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.1/109.3 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 109.3/109.3 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.24.0-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.8/3.7 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.4/3.7 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 6.6 MB/s eta 0:00:00\n",
      "Using cached pennylane-0.42.3-py3-none-any.whl (4.8 MB)\n",
      "Using cached autoray-0.7.2-py3-none-any.whl (930 kB)\n",
      "Using cached medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.6/1.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 7.2 MB/s eta 0:00:00\n",
      "Using cached pennylane_lightning-0.42.0-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "Using cached rustworkx-0.17.1-cp39-abi3-win_amd64.whl (2.1 MB)\n",
      "Using cached scipy_openblas32-0.3.30.0.6-py3-none-win_amd64.whl (7.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached autograd-1.8.0-py3-none-any.whl (51 kB)\n",
      "Using cached cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Using cached diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached scikit_image-0.25.2-cp310-cp310-win_amd64.whl (12.8 MB)\n",
      "Using cached imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Using cached tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
      "Using cached scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: pytz, mpmath, appdirs, tzdata, tomlkit, tifffile, threadpoolctl, termcolor, sympy, scipy-openblas32, scipy, rustworkx, networkx, MarkupSafe, lazy-loader, joblib, imageio, gast, fsspec, filelock, cachetools, autoray, autograd, astunparse, scikit-learn, scikit-image, pandas, jinja2, fire, diastatic-malt, torch, torchvision, medmnist, pennylane-lightning, pennylane\n",
      "\n",
      "   ----------------------------------------  0/35 [pytz]\n",
      "   ----------------------------------------  0/35 [pytz]\n",
      "   ----------------------------------------  0/35 [pytz]\n",
      "   ----------------------------------------  0/35 [pytz]\n",
      "   ----------------------------------------  0/35 [pytz]\n",
      "   ----------------------------------------  0/35 [pytz]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   - --------------------------------------  1/35 [mpmath]\n",
      "   --- ------------------------------------  3/35 [tzdata]\n",
      "   --- ------------------------------------  3/35 [tzdata]\n",
      "   --- ------------------------------------  3/35 [tzdata]\n",
      "   --- ------------------------------------  3/35 [tzdata]\n",
      "   --- ------------------------------------  3/35 [tzdata]\n",
      "   ---- -----------------------------------  4/35 [tomlkit]\n",
      "   ---- -----------------------------------  4/35 [tomlkit]\n",
      "   ----- ----------------------------------  5/35 [tifffile]\n",
      "   ----- ----------------------------------  5/35 [tifffile]\n",
      "   ----- ----------------------------------  5/35 [tifffile]\n",
      "   ------ ---------------------------------  6/35 [threadpoolctl]\n",
      "   -------- -------------------------------  7/35 [termcolor]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   --------- ------------------------------  8/35 [sympy]\n",
      "   ---------- -----------------------------  9/35 [scipy-openblas32]\n",
      "   ---------- -----------------------------  9/35 [scipy-openblas32]\n",
      "   ---------- -----------------------------  9/35 [scipy-openblas32]\n",
      "   ---------- -----------------------------  9/35 [scipy-openblas32]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ----------- ---------------------------- 10/35 [scipy]\n",
      "   ------------ --------------------------- 11/35 [rustworkx]\n",
      "   ------------ --------------------------- 11/35 [rustworkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   ------------- -------------------------- 12/35 [networkx]\n",
      "   -------------- ------------------------- 13/35 [MarkupSafe]\n",
      "   ---------------- ----------------------- 14/35 [lazy-loader]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ----------------- ---------------------- 15/35 [joblib]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------ --------------------- 16/35 [imageio]\n",
      "   ------------------- -------------------- 17/35 [gast]\n",
      "   ------------------- -------------------- 17/35 [gast]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   -------------------- ------------------- 18/35 [fsspec]\n",
      "   --------------------- ------------------ 19/35 [filelock]\n",
      "   --------------------- ------------------ 19/35 [filelock]\n",
      "   ---------------------- ----------------- 20/35 [cachetools]\n",
      "   ---------------------- ----------------- 20/35 [cachetools]\n",
      "   ------------------------ --------------- 21/35 [autoray]\n",
      "   ------------------------ --------------- 21/35 [autoray]\n",
      "   ------------------------ --------------- 21/35 [autoray]\n",
      "   ------------------------- -------------- 22/35 [autograd]\n",
      "   ------------------------- -------------- 22/35 [autograd]\n",
      "   ------------------------- -------------- 22/35 [autograd]\n",
      "   ------------------------- -------------- 22/35 [autograd]\n",
      "   ------------------------- -------------- 22/35 [autograd]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   --------------------------- ------------ 24/35 [scikit-learn]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ---------------------------- ----------- 25/35 [scikit-image]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ----------------------------- ---------- 26/35 [pandas]\n",
      "   ------------------------------ --------- 27/35 [jinja2]\n",
      "   ------------------------------ --------- 27/35 [jinja2]\n",
      "   ------------------------------ --------- 27/35 [jinja2]\n",
      "   -------------------------------- ------- 28/35 [fire]\n",
      "   -------------------------------- ------- 28/35 [fire]\n",
      "   -------------------------------- ------- 28/35 [fire]\n",
      "   -------------------------------- ------- 28/35 [fire]\n",
      "   -------------------------------- ------- 28/35 [fire]\n",
      "   -------------------------------- ------- 28/35 [fire]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   --------------------------------- ------ 29/35 [diastatic-malt]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ---------------------------------- ----- 30/35 [torch]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ----------------------------------- ---- 31/35 [torchvision]\n",
      "   ------------------------------------ --- 32/35 [medmnist]\n",
      "   ------------------------------------- -- 33/35 [pennylane-lightning]\n",
      "   ------------------------------------- -- 33/35 [pennylane-lightning]\n",
      "   ------------------------------------- -- 33/35 [pennylane-lightning]\n",
      "   ------------------------------------- -- 33/35 [pennylane-lightning]\n",
      "   ------------------------------------- -- 33/35 [pennylane-lightning]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   -------------------------------------- - 34/35 [pennylane]\n",
      "   ---------------------------------------- 35/35 [pennylane]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 appdirs-1.4.4 astunparse-1.6.3 autograd-1.8.0 autoray-0.7.2 cachetools-6.2.1 diastatic-malt-2.15.2 filelock-3.20.0 fire-0.7.1 fsspec-2025.10.0 gast-0.6.0 imageio-2.37.0 jinja2-3.1.6 joblib-1.5.2 lazy-loader-0.4 medmnist-3.0.2 mpmath-1.3.0 networkx-3.4.2 pandas-2.3.3 pennylane-0.42.3 pennylane-lightning-0.42.0 pytz-2025.2 rustworkx-0.17.1 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.15.3 scipy-openblas32-0.3.30.0.6 sympy-1.14.0 termcolor-3.2.0 threadpoolctl-3.6.0 tifffile-2025.5.10 tomlkit-0.13.3 torch-2.9.0 torchvision-0.24.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    " #Uncomment and run if you need to install packages\n",
    " %pip install torch torchvision numpy pennylane medmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89333376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.9.0+cpu\n",
      "PennyLane version: 0.42.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pennylane as qml\n",
    "from pennylane.qnn import TorchLayer\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PennyLane version: {qml.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a80afb",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c01a2bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Qubits: 4\n",
      "  Quantum layers: 2\n",
      "  Latent dimension: 16\n",
      "  Image size: 64x64\n",
      "  Batch size: 10\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 4                 # set desired number of qubits\n",
    "n_layers = 2                 # set desired number of quantum layers\n",
    "latent_dim = 2**n_qubits     # latent dimension = 2^n_qubits\n",
    "img_size = 64              # set desired image size (28, 64, 128, 224)\n",
    "batch_size = 10\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Qubits: {n_qubits}\")\n",
    "print(f\"  Quantum layers: {n_layers}\")\n",
    "print(f\"  Latent dimension: {latent_dim}\")\n",
    "print(f\"  Image size: {img_size}x{img_size}\")\n",
    "print(f\"  Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74359e0",
   "metadata": {},
   "source": [
    "## Load Data from preprocess.py\n",
    "\n",
    "We import the data loaders from our preprocess.py file to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e8e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Training samples: 78468\n",
      "Test samples: 22433\n",
      "Training batches: 2452\n",
      "Test batches: 702\n"
     ]
    }
   ],
   "source": [
    "# Import data loaders from preprocess.py\n",
    "from preprocess import train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd582d",
   "metadata": {},
   "source": [
    "Filter Out Double-Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14fc1bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for single-label images only...\n",
      " Filtered Training: 21602 single-label images (2160 batches)\n",
      " Filtered Test: 6259 single-label images (626 batches)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "print(\"Filtering for single-label images only...\")\n",
    "\n",
    "# Filter training set\n",
    "train_single_label_indices = []\n",
    "for i in range(len(train_dataset)):\n",
    "    _, label = train_dataset[i]\n",
    "    if label.sum() == 1:  # Only one condition present\n",
    "        train_single_label_indices.append(i)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_single_label_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, drop_last=True)\n",
    "\n",
    "# Filter test set\n",
    "test_single_label_indices = []\n",
    "for i in range(len(test_dataset)):\n",
    "    _, label = test_dataset[i]\n",
    "    if label.sum() == 1:\n",
    "        test_single_label_indices.append(i)\n",
    "\n",
    "test_dataset = Subset(test_dataset, test_single_label_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, drop_last=False)\n",
    "\n",
    "print(f\" Filtered Training: {len(train_dataset)} single-label images ({len(train_loader)} batches)\")\n",
    "print(f\" Filtered Test: {len(test_dataset)} single-label images ({len(test_loader)} batches)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf487ff",
   "metadata": {},
   "source": [
    "## Classical Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim, img_size):\n",
    "        \"\"\"\n",
    "        Encoder produces a `latent_dim`-dimensional vector from input images.\n",
    "\n",
    "        Args:\n",
    "            latent_dim (int): dimensionality of the encoder output. Must be provided\n",
    "                by the notebook settings (e.g. `latent_dim = 2**n_qubits`).\n",
    "            img_size (int): input image size (H=W). Must be provided by the settings\n",
    "                cell so the model internals compute shapes correctly.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert isinstance(latent_dim, int) and latent_dim > 0, \"latent_dim must be a positive int\"\n",
    "        assert isinstance(img_size, int) and img_size > 0, \"img_size must be a positive int\"\n",
    "\n",
    "        self.h8 = img_size // 8\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Initialize encoder weights properly\n",
    "        for m in self.encoder.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)  # (B,latent_dim)\n",
    "        return z  # Return unnormalized z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4a989",
   "metadata": {},
   "source": [
    "## Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6e4fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum device initialized: <default.qubit device (wires=6) at 0x1f167570940>\n",
      "QuantumHead with EXTREME safety checks!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---- quantum device ----\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def qnode(inputs, weights):\n",
    "    # inputs: shape (2**n_qubits,), NOT batched - single sample\n",
    "    qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class QuantumHead(nn.Module):\n",
    "    def __init__(self, n_layers, n_qubits, n_classes, latent_dim):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.encoder_fc = nn.Linear(latent_dim, 2**n_qubits)\n",
    "        \n",
    "        # Better weight initialization\n",
    "        nn.init.xavier_uniform_(self.encoder_fc.weight, gain=0.01)  # Even smaller gain\n",
    "        nn.init.zeros_(self.encoder_fc.bias)\n",
    "        \n",
    "        # Initialize quantum weights manually\n",
    "        self.q_weights = nn.Parameter(torch.randn(n_layers, n_qubits, 3) * 0.001)  # Very small initialization\n",
    "        \n",
    "        # Readout layer\n",
    "        self.readout = nn.Linear(n_qubits, n_classes)\n",
    "\n",
    "    def forward(self, h):\n",
    "        # h: (B, latent_dim)\n",
    "        batch_size = h.shape[0]\n",
    "        \n",
    "        # Check input for NaN\n",
    "        if torch.isnan(h).any() or torch.isinf(h).any():\n",
    "            print(\" NaN/Inf in input h!\")\n",
    "            h = torch.nan_to_num(h, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        z = self.encoder_fc(h)  # (B, 2**n_qubits)\n",
    "        \n",
    "        # Aggressive NaN/Inf replacement\n",
    "        z = torch.nan_to_num(z, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        # Clamp BEFORE normalization\n",
    "        z = torch.clamp(z, min=-5, max=5)\n",
    "        \n",
    "        # Normalize per row with extreme safety\n",
    "        norm = torch.sqrt(torch.sum(z**2, dim=1, keepdim=True) + 1e-10)\n",
    "        \n",
    "        # If norm is too small, replace entire row with uniform vector\n",
    "        small_norm_mask = norm.squeeze() < 1e-6\n",
    "        if small_norm_mask.any():\n",
    "            print(f\" {small_norm_mask.sum().item()} rows with near-zero norm, fixing...\")\n",
    "            uniform_vec = torch.ones(2**self.n_qubits, device=z.device) / np.sqrt(2**self.n_qubits)\n",
    "            z[small_norm_mask] = uniform_vec\n",
    "            norm = torch.sqrt(torch.sum(z**2, dim=1, keepdim=True) + 1e-10)\n",
    "        \n",
    "        z_normalized = z / norm\n",
    "        \n",
    "        # Final verification\n",
    "        z_normalized = torch.nan_to_num(z_normalized, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        # Re-normalize after NaN replacement\n",
    "        final_norm = torch.sqrt(torch.sum(z_normalized**2, dim=1, keepdim=True) + 1e-10)\n",
    "        z_normalized = z_normalized / final_norm\n",
    "        \n",
    "        # Manual batching - process one sample at a time\n",
    "        results = []\n",
    "        for i in range(batch_size):\n",
    "            single_input = z_normalized[i].detach().clone()\n",
    "            \n",
    "            # Triple check this specific sample\n",
    "            if torch.isnan(single_input).any() or torch.isinf(single_input).any():\n",
    "                print(f\" Sample {i} still has NaN/Inf! Using uniform vector.\")\n",
    "                single_input = torch.ones(2**self.n_qubits, device=z.device) / np.sqrt(2**self.n_qubits)\n",
    "            \n",
    "            # Verify norm is close to 1\n",
    "            sample_norm = torch.sqrt(torch.sum(single_input**2))\n",
    "            if abs(sample_norm - 1.0) > 0.1:\n",
    "                print(f\" Sample {i} norm is {sample_norm.item():.4f}, renormalizing...\")\n",
    "                single_input = single_input / (sample_norm + 1e-10)\n",
    "            \n",
    "            try:\n",
    "                # Run quantum circuit on single sample\n",
    "                expvals = qnode(single_input, self.q_weights)\n",
    "                expvals_tensor = torch.stack(expvals).float()\n",
    "            except Exception as e:\n",
    "                print(f\" Quantum circuit failed for sample {i}: {e}\")\n",
    "                # Return zeros if circuit fails\n",
    "                expvals_tensor = torch.zeros(self.n_qubits, device=z.device)\n",
    "            \n",
    "            results.append(expvals_tensor)\n",
    "        \n",
    "        # Stack all results back into batch\n",
    "        expvals_batch = torch.stack(results)  # (B, n_qubits)\n",
    "        \n",
    "        # Final readout layer\n",
    "        return self.readout(expvals_batch)\n",
    "\n",
    "print(f\"Quantum device initialized: {dev}\")\n",
    "print(\"QuantumHead with EXTREME safety checks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb7783",
   "metadata": {},
   "source": [
    "## Hybrid Quantum-Classical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa6eb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridQML(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, n_classes=14):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(latent_dim=latent_dim, img_size=img_size)\n",
    "        self.qhead = QuantumHead(n_layers=n_layers, n_qubits=n_qubits, n_classes=n_classes, latent_dim=latent_dim)\n",
    "\n",
    "    def forward(self, x, return_recon=False):\n",
    "        h = self.enc(x)\n",
    "        out = self.qhead(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051572bf",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a244a507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      " Model recreated with dtype fix!\n",
      "Parameters: 105,222\n",
      "Training functions defined successfully!\n",
      "Model has 105222 parameters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = HybridQML(img_size=img_size, latent_dim=latent_dim, n_classes=14).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=5e-5,\n",
    "    weight_decay=1e-5,\n",
    "    eps=1e-7\n",
    ")\n",
    "\n",
    "clf_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\" Model recreated with dtype fix!\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    window_start = time.time()\n",
    "    \n",
    "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        logits = model(imgs, return_recon=True)\n",
    "        loss = clf_criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # GRADIENT CLIPPING - prevents NaN!\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item() * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "        \n",
    "\n",
    "        avg_size = 10\n",
    "        if batch_idx % avg_size == 0:  \n",
    "            # measure total time for the last 10 batches\n",
    "            elapsed = time.time() - window_start\n",
    "            avg_time = elapsed / avg_size if batch_idx != 0 else elapsed\n",
    "            print(\n",
    "                f\"  Batch {batch_idx+1}/{len(train_loader)}, \"\n",
    "                f\"Avg Loss: {total/n:.4f}, \"\n",
    "                f\"Avg Time per batch: {avg_time:.4f}s\"\n",
    "            )\n",
    "            window_start = time.time()  # reset window\n",
    "            \n",
    "\n",
    "    print(f\"Epoch {epoch}: train loss = {total/n:.4f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = clf_criterion(logits, labels)\n",
    "        total += loss.item() * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "    print(f\"Test BCEWithLogits loss = {total/n:.4f}\")\n",
    "\n",
    "print(\"Training functions defined successfully!\")\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28252c5d",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd7e3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "  Batch 1/2160, Avg Loss: 0.6846, Avg Time per batch: 9.9829s\n",
      "  Batch 11/2160, Avg Loss: 0.6798, Avg Time per batch: 10.7231s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     evaluate()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[1;32mIn[23], line 32\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m clf_criterion(logits, labels)\n\u001b[0;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 32\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# GRADIENT CLIPPING - prevents NaN!\u001b[39;00m\n\u001b[0;32m     35\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    843\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\torch\\autograd\\function.py:315\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    313\u001b[0m     )\n\u001b[0;32m    314\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:101\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_backward\u001b[1;34m(ctx, *flat_grad_outputs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_backward\u001b[39m(ctx, \u001b[38;5;241m*\u001b[39mflat_grad_outputs):\n\u001b[0;32m    100\u001b[0m     grad_outputs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_grad_outputs, ctx\u001b[38;5;241m.\u001b[39m_out_struct)\n\u001b[1;32m--> 101\u001b[0m     grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[43morig_bw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# None corresponds to the diff of out_struct_holder\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(grad_inputs)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:190\u001b[0m, in \u001b[0;36mExecuteTapes.backward\u001b[1;34m(ctx, *dy)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Torch obeys the dL/dz_conj convention instead of the\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# dL/dz convention of PennyLane, autograd and jax. This converts between the formats\u001b[39;00m\n\u001b[0;32m    189\u001b[0m dy \u001b[38;5;241m=\u001b[39m _recursive_conj(dy)\n\u001b[1;32m--> 190\u001b[0m vjps \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# split tensor into separate entries\u001b[39;00m\n\u001b[0;32m    192\u001b[0m unpacked_vjps \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\workflow\\jacobian_products.py:331\u001b[0m, in \u001b[0;36mTransformJacobianProducts.compute_vjp\u001b[1;34m(self, tapes, dy)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_vjps(jacs, dy, tapes)\n\u001b[0;32m    327\u001b[0m vjp_tapes, processing_fn \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mgradients\u001b[38;5;241m.\u001b[39mbatch_vjp(\n\u001b[0;32m    328\u001b[0m     tapes, dy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_transform, gradient_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_kwargs\n\u001b[0;32m    329\u001b[0m )\n\u001b[1;32m--> 331\u001b[0m vjp_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvjp_tapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(processing_fn(vjp_results))\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\workflow\\run.py:253\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner_execute\u001b[39m(tapes: QuantumScriptBatch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultBatch:\n\u001b[0;32m    245\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execution that occurs within a ML framework boundary.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    Closure Variables:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m        device (qml.devices.Device): a Pennylane device\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m     transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m \u001b[43minner_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[0;32m    256\u001b[0m         results \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mexecute(transformed_tapes, execution_config\u001b[38;5;241m=\u001b[39mexecution_config)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\transforms\\core\\transform_program.py:501\u001b[0m, in \u001b[0;36mTransformProgram.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaxpr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_jaxpr(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_tapes(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\transforms\\core\\transform_program.py:431\u001b[0m, in \u001b[0;36mTransformProgram.__call_tapes\u001b[1;34m(self, tapes)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argnums \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unsubscriptable-object\u001b[39;00m\n\u001b[0;32m    430\u001b[0m     tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m argnums[tape_idx]\n\u001b[1;32m--> 431\u001b[0m new_tapes, fn \u001b[38;5;241m=\u001b[39m transform(tape, \u001b[38;5;241m*\u001b[39mtargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtkwargs)\n\u001b[0;32m    432\u001b[0m execution_tapes\u001b[38;5;241m.\u001b[39mextend(new_tapes)\n\u001b[0;32m    434\u001b[0m fns\u001b[38;5;241m.\u001b[39mappend(fn)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:84\u001b[0m, in \u001b[0;36mconvert_to_numpy_parameters\u001b[1;34m(tape)\u001b[0m\n\u001b[0;32m     82\u001b[0m new_ops \u001b[38;5;241m=\u001b[39m (_convert_op_to_numpy_data(op) \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m     83\u001b[0m new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[1;32m---> 84\u001b[0m new_circuit \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_measurements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_params\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnull_postprocessing\u001b[39m(results):\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A postprocesing function returned by a transform that only converts the batch of results\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    into a result for a single ``QuantumTape``.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\tape\\qscript.py:194\u001b[0m, in \u001b[0;36mQuantumScript.__init__\u001b[1;34m(self, ops, measurements, shots, trainable_params)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    189\u001b[0m     ops: Optional[Iterable[Operator]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m     trainable_params: Optional[Sequence[\u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    193\u001b[0m ):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ops \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m ops \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measurements \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m measurements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(measurements)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shots \u001b[38;5;241m=\u001b[39m Shots(shots)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:82\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;129m@transform\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_to_numpy_parameters\u001b[39m(tape: QuantumScript) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[QuantumScriptBatch, PostprocessingFn]:\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transforms a circuit to one with purely numpy parameters.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     new_ops \u001b[38;5;241m=\u001b[39m (\u001b[43m_convert_op_to_numpy_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m     83\u001b[0m     new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[0;32m     84\u001b[0m     new_circuit \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[0;32m     85\u001b[0m         new_ops, new_measurements, shots\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mshots, trainable_params\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mtrainable_params\n\u001b[0;32m     86\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:30\u001b[0m, in \u001b[0;36m_convert_op_to_numpy_data\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Use operator method to change parameters when it become available\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mbind_new_parameters(op, \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:814\u001b[0m, in \u001b[0;36munwrap\u001b[1;34m(values, max_depth)\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_val, ndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01melse\u001b[39;00m new_val\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    816\u001b[0m     np\u001b[38;5;241m.\u001b[39mto_numpy(values, max_depth\u001b[38;5;241m=\u001b[39mmax_depth)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ArrayBox)\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mto_numpy(values)\n\u001b[0;32m    819\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:814\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_val, ndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01melse\u001b[39;00m new_val\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(values)(\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m values)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    816\u001b[0m     np\u001b[38;5;241m.\u001b[39mto_numpy(values, max_depth\u001b[38;5;241m=\u001b[39mmax_depth)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ArrayBox)\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mto_numpy(values)\n\u001b[0;32m    819\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:809\u001b[0m, in \u001b[0;36munwrap.<locals>.convert\u001b[1;34m(val)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unwrap(val)\n\u001b[0;32m    808\u001b[0m new_val \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 809\u001b[0m     np\u001b[38;5;241m.\u001b[39mto_numpy(val, max_depth\u001b[38;5;241m=\u001b[39mmax_depth) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, ArrayBox) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m )\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_val, ndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01melse\u001b[39;00m new_val\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\autoray\\autoray.py:81\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m backend \u001b[38;5;241m=\u001b[39m _choose_backend(fn, args, kwargs, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[0;32m     80\u001b[0m func \u001b[38;5;241m=\u001b[39m get_lib_fn(backend, fn)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\siche\\AppData\\Local\\PyMol\\lib\\site-packages\\pennylane\\math\\single_dispatch.py:617\u001b[0m, in \u001b[0;36m_to_numpy_torch\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_conj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mis_conj():  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;66;03m# The following line is only covered if using Torch <v1.10.0\u001b[39;00m\n\u001b[0;32m    615\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mresolve_conj()\n\u001b[1;32m--> 617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    train_one_epoch(epoch)\n",
    "    evaluate()\n",
    "    print()\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ba419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"hybrid_qml_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
