{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6e1489",
   "metadata": {},
   "source": [
    "# Quantum-Classical Hybrid Autoencoder for Medical Image Classification\n",
    "\n",
    "This notebook implements a hybrid quantum-classical model for chest X-ray classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-deps",
   "metadata": {},
   "source": [
    "## Installation (Run if packages missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "install-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if you need to install packages\n",
    "# %pip install torch torchvision numpy pennylane medmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89333376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.9.0+cu130\n",
      "PennyLane version: 0.43.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from pennylane.qnn import TorchLayer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PennyLane version: {qml.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a80afb",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c01a2bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Qubits: 6\n",
      "  Quantum layers: 5\n",
      "  Latent dimension: 64\n",
      "  Image size: 224x224\n",
      "  Batch size: 64\n",
      "  Epochs: 100\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 6                 # set desired number of qubits\n",
    "n_layers = 5                 # set desired number of quantum layers\n",
    "latent_dim = 2**n_qubits     # latent dimension = 2^n_qubits\n",
    "img_size = 224               # set desired image size (28, 64, 128, 224)\n",
    "batch_size = 64\n",
    "n_epochs = 100\n",
    "n_workers = 4\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Qubits: {n_qubits}\")\n",
    "print(f\"  Quantum layers: {n_layers}\")\n",
    "print(f\"  Latent dimension: {latent_dim}\")\n",
    "print(f\"  Image size: {img_size}x{img_size}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Epochs: {n_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74359e0",
   "metadata": {},
   "source": [
    "## Load Data from preprocess.py\n",
    "\n",
    "We import the data loaders from our preprocess.py file to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24e8e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Training samples: 78468\n",
      "Test samples: 22433\n"
     ]
    }
   ],
   "source": [
    "# Import data loaders from preprocess.py\n",
    "from preprocess import train_dataset, test_dataset\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd582d",
   "metadata": {},
   "source": [
    "Filter Out Double-Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14fc1bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Training: 21602 single-label images (337 batches)\n",
      "Filtered Test: 6259 single-label images (98 batches)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# Filter training set\n",
    "train_single_label_indices = []\n",
    "for i in range(len(train_dataset)):\n",
    "    _, label = train_dataset[i]\n",
    "    if label.sum() == 1:  # Only one condition present\n",
    "        train_single_label_indices.append(i)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_single_label_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=n_workers, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# Filter test set\n",
    "test_single_label_indices = []\n",
    "for i in range(len(test_dataset)):\n",
    "    _, label = test_dataset[i]\n",
    "    if label.sum() == 1:\n",
    "        test_single_label_indices.append(i)\n",
    "\n",
    "test_dataset = Subset(test_dataset, test_single_label_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=n_workers, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "print(f\"Filtered Training: {len(train_dataset)} single-label images ({len(train_loader)} batches)\")\n",
    "print(f\"Filtered Test: {len(test_dataset)} single-label images ({len(test_loader)} batches)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf487ff",
   "metadata": {},
   "source": [
    "## Classical Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07cc5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64, img_size=224):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x): return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4a989",
   "metadata": {},
   "source": [
    "## Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6e4fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum device initialized: <lightning.qubit device (wires=6) at 0x168e50b82b0>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---- quantum device ----\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "#dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def qnode(inputs, weights):\n",
    "    qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class QuantumHead(nn.Module):\n",
    "    def __init__(self, n_layers, n_qubits, n_classes, latent_dim):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.encoder_fc = nn.Linear(latent_dim, 2**n_qubits)\n",
    "        nn.init.xavier_uniform_(self.encoder_fc.weight, gain=0.01)\n",
    "        nn.init.zeros_(self.encoder_fc.bias)\n",
    "        self.q_weights = nn.Parameter(torch.randn(n_layers, n_qubits, 3) * 0.001)\n",
    "        self.readout = nn.Linear(n_qubits, n_classes)\n",
    "\n",
    "    def _prepare_quantum_input(self, h):\n",
    "        z = self.encoder_fc(h)\n",
    "        z = torch.nan_to_num(torch.clamp(z, -5, 5))\n",
    "        norm = torch.sqrt(torch.sum(z**2, dim=1, keepdim=True) + 1e-10)\n",
    "        if (norm.squeeze() < 1e-6).any():\n",
    "            uniform = torch.ones(2**self.n_qubits, device=z.device) / np.sqrt(2**self.n_qubits)\n",
    "            z[norm.squeeze() < 1e-6] = uniform\n",
    "            norm = torch.sqrt(torch.sum(z**2, dim=1, keepdim=True) + 1e-10)\n",
    "        return z / norm\n",
    "    \n",
    "    def forward(self, h):\n",
    "        device = h.device\n",
    "        z_norm = self._prepare_quantum_input(h).cpu()\n",
    "        q_w_cpu = self.q_weights.cpu()\n",
    "        results = []\n",
    "        for i in range(h.shape[0]):\n",
    "            try:\n",
    "                expvals = qnode_single(z_norm[i].detach(), q_w_cpu)\n",
    "                results.append(torch.stack(expvals).float())\n",
    "            except:\n",
    "                results.append(torch.zeros(self.n_qubits))\n",
    "        return self.readout(torch.stack(results).to(device))\n",
    "\n",
    "print(f\"Quantum device initialized: {dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb7783",
   "metadata": {},
   "source": [
    "## Hybrid Quantum-Classical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa6eb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridQML(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, n_classes=14):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(latent_dim, img_size)\n",
    "        self.qhead = QuantumHead(n_layers, n_qubits, n_classes, latent_dim)\n",
    "    def forward(self, x, return_recon=False):\n",
    "        return self.qhead(self.enc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051572bf",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "849b0581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model initialized: 105,276 parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = HybridQML(img_size=img_size, latent_dim=latent_dim, n_classes=14).to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=5e-5,\n",
    "    weight_decay=1e-5,\n",
    "    eps=1e-7\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f\"Model initialized: {sum(p.numel() for p in model.parameters()):,} parameters\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a244a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch}/{n_epochs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.float().to(device)\n",
    "        logits = model(imgs, True)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total += loss.item() * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "        \n",
    "        if i % max(1, len(train_loader) // 4) == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            progress = (i + 1) / len(train_loader) * 100\n",
    "            print(f\"  [{progress:5.1f}%] Batch {i:3d}/{len(train_loader)} | Loss: {total/n:.4f} | Time: {elapsed:.1f}s\")\n",
    "            \n",
    "    epoch_time = time.time() - start_time\n",
    "    avg_loss = total / n\n",
    "    print(f\"\\nEpoch {epoch} complete in {epoch_time:.1f}s | Train Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss, epoch_time\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.float().to(device)\n",
    "        loss = criterion(model(imgs), labels)\n",
    "        total += loss.item() * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "    return total / n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28252c5d",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd7e3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 epochs...\n",
      "\n",
      "\n",
      "============================================================\n",
      "EPOCH 1/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.7418 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.7370 | Time: 1.2s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.7362 | Time: 2.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.7353 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.7343 | Time: 3.5s\n",
      "\n",
      "Epoch 1 complete in 3.5s | Train Loss: 0.7343\n",
      "Test Loss: 0.7303 | Best: 0.7303 (Epoch 1)\n",
      "\n",
      "============================================================\n",
      "EPOCH 2/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.7327 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.7296 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.7286 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.7276 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.7267 | Time: 3.2s\n",
      "\n",
      "Epoch 2 complete in 3.2s | Train Loss: 0.7267\n",
      "Test Loss: 0.7228 | Best: 0.7228 (Epoch 2)\n",
      "\n",
      "============================================================\n",
      "EPOCH 3/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.7234 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.7219 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.7211 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.7202 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.7193 | Time: 3.3s\n",
      "\n",
      "Epoch 3 complete in 3.3s | Train Loss: 0.7193\n",
      "Test Loss: 0.7154 | Best: 0.7154 (Epoch 3)\n",
      "\n",
      "============================================================\n",
      "EPOCH 4/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.7192 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.7149 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.7139 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.7130 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.7119 | Time: 3.1s\n",
      "\n",
      "Epoch 4 complete in 3.1s | Train Loss: 0.7119\n",
      "Test Loss: 0.7081 | Best: 0.7081 (Epoch 4)\n",
      "\n",
      "============================================================\n",
      "EPOCH 5/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.7063 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.7073 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.7064 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.7055 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.7047 | Time: 3.3s\n",
      "\n",
      "Epoch 5 complete in 3.3s | Train Loss: 0.7047\n",
      "Test Loss: 0.7009 | Best: 0.7009 (Epoch 5)\n",
      "\n",
      "============================================================\n",
      "EPOCH 6/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.7023 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.7001 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6993 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6984 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6975 | Time: 3.2s\n",
      "\n",
      "Epoch 6 complete in 3.2s | Train Loss: 0.6975\n",
      "Test Loss: 0.6937 | Best: 0.6937 (Epoch 6)\n",
      "\n",
      "============================================================\n",
      "EPOCH 7/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6932 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6929 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6921 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6913 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6904 | Time: 3.7s\n",
      "\n",
      "Epoch 7 complete in 3.7s | Train Loss: 0.6904\n",
      "Test Loss: 0.6867 | Best: 0.6867 (Epoch 7)\n",
      "\n",
      "============================================================\n",
      "EPOCH 8/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6867 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6861 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6850 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6842 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6834 | Time: 3.7s\n",
      "\n",
      "Epoch 8 complete in 3.7s | Train Loss: 0.6834\n",
      "Test Loss: 0.6797 | Best: 0.6797 (Epoch 8)\n",
      "\n",
      "============================================================\n",
      "EPOCH 9/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6789 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6792 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6783 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6773 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6764 | Time: 3.7s\n",
      "\n",
      "Epoch 9 complete in 3.7s | Train Loss: 0.6764\n",
      "Test Loss: 0.6728 | Best: 0.6728 (Epoch 9)\n",
      "\n",
      "============================================================\n",
      "EPOCH 10/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6738 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6721 | Time: 1.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6711 | Time: 2.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6704 | Time: 3.1s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6696 | Time: 4.0s\n",
      "\n",
      "Epoch 10 complete in 4.0s | Train Loss: 0.6696\n",
      "Test Loss: 0.6660 | Best: 0.6660 (Epoch 10)\n",
      "\n",
      "============================================================\n",
      "EPOCH 11/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6662 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6653 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6645 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6636 | Time: 2.6s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6628 | Time: 3.4s\n",
      "\n",
      "Epoch 11 complete in 3.4s | Train Loss: 0.6628\n",
      "Test Loss: 0.6592 | Best: 0.6592 (Epoch 11)\n",
      "\n",
      "============================================================\n",
      "EPOCH 12/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6642 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6586 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6576 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6569 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6561 | Time: 3.2s\n",
      "\n",
      "Epoch 12 complete in 3.2s | Train Loss: 0.6561\n",
      "Test Loss: 0.6525 | Best: 0.6525 (Epoch 12)\n",
      "\n",
      "============================================================\n",
      "EPOCH 13/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6535 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6521 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6512 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6503 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6494 | Time: 3.2s\n",
      "\n",
      "Epoch 13 complete in 3.2s | Train Loss: 0.6494\n",
      "Test Loss: 0.6459 | Best: 0.6459 (Epoch 13)\n",
      "\n",
      "============================================================\n",
      "EPOCH 14/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6462 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6450 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6444 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6437 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6428 | Time: 3.2s\n",
      "\n",
      "Epoch 14 complete in 3.2s | Train Loss: 0.6428\n",
      "Test Loss: 0.6394 | Best: 0.6394 (Epoch 14)\n",
      "\n",
      "============================================================\n",
      "EPOCH 15/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6395 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6387 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6379 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6372 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6363 | Time: 3.2s\n",
      "\n",
      "Epoch 15 complete in 3.2s | Train Loss: 0.6363\n",
      "Test Loss: 0.6329 | Best: 0.6329 (Epoch 15)\n",
      "\n",
      "============================================================\n",
      "EPOCH 16/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6325 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6323 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6316 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6307 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6299 | Time: 3.2s\n",
      "\n",
      "Epoch 16 complete in 3.2s | Train Loss: 0.6299\n",
      "Test Loss: 0.6265 | Best: 0.6265 (Epoch 16)\n",
      "\n",
      "============================================================\n",
      "EPOCH 17/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6264 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6258 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6250 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6243 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6235 | Time: 3.2s\n",
      "\n",
      "Epoch 17 complete in 3.2s | Train Loss: 0.6235\n",
      "Test Loss: 0.6202 | Best: 0.6202 (Epoch 17)\n",
      "\n",
      "============================================================\n",
      "EPOCH 18/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6173 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6196 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6189 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6180 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6172 | Time: 3.2s\n",
      "\n",
      "Epoch 18 complete in 3.2s | Train Loss: 0.6172\n",
      "Test Loss: 0.6140 | Best: 0.6140 (Epoch 18)\n",
      "\n",
      "============================================================\n",
      "EPOCH 19/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6119 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6133 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6125 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6118 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6110 | Time: 3.2s\n",
      "\n",
      "Epoch 19 complete in 3.2s | Train Loss: 0.6110\n",
      "Test Loss: 0.6078 | Best: 0.6078 (Epoch 19)\n",
      "\n",
      "============================================================\n",
      "EPOCH 20/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6099 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6072 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6064 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.6056 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.6049 | Time: 3.2s\n",
      "\n",
      "Epoch 20 complete in 3.2s | Train Loss: 0.6049\n",
      "Test Loss: 0.6016 | Best: 0.6016 (Epoch 20)\n",
      "\n",
      "============================================================\n",
      "EPOCH 21/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.6021 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.6010 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.6001 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5994 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5988 | Time: 3.3s\n",
      "\n",
      "Epoch 21 complete in 3.3s | Train Loss: 0.5988\n",
      "Test Loss: 0.5956 | Best: 0.5956 (Epoch 21)\n",
      "\n",
      "============================================================\n",
      "EPOCH 22/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5937 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5951 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5943 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5935 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5927 | Time: 3.2s\n",
      "\n",
      "Epoch 22 complete in 3.2s | Train Loss: 0.5927\n",
      "Test Loss: 0.5896 | Best: 0.5896 (Epoch 22)\n",
      "\n",
      "============================================================\n",
      "EPOCH 23/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5893 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5891 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5883 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5875 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5868 | Time: 3.3s\n",
      "\n",
      "Epoch 23 complete in 3.3s | Train Loss: 0.5868\n",
      "Test Loss: 0.5837 | Best: 0.5837 (Epoch 23)\n",
      "\n",
      "============================================================\n",
      "EPOCH 24/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5851 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5833 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5823 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5817 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5809 | Time: 3.7s\n",
      "\n",
      "Epoch 24 complete in 3.7s | Train Loss: 0.5809\n",
      "Test Loss: 0.5778 | Best: 0.5778 (Epoch 24)\n",
      "\n",
      "============================================================\n",
      "EPOCH 25/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5782 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5771 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5765 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5758 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5751 | Time: 3.8s\n",
      "\n",
      "Epoch 25 complete in 3.8s | Train Loss: 0.5751\n",
      "Test Loss: 0.5720 | Best: 0.5720 (Epoch 25)\n",
      "\n",
      "============================================================\n",
      "EPOCH 26/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5718 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5715 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5708 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5700 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5693 | Time: 3.7s\n",
      "\n",
      "Epoch 26 complete in 3.7s | Train Loss: 0.5693\n",
      "Test Loss: 0.5663 | Best: 0.5663 (Epoch 26)\n",
      "\n",
      "============================================================\n",
      "EPOCH 27/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5671 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5655 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5650 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5643 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5636 | Time: 3.2s\n",
      "\n",
      "Epoch 27 complete in 3.2s | Train Loss: 0.5636\n",
      "Test Loss: 0.5606 | Best: 0.5606 (Epoch 27)\n",
      "\n",
      "============================================================\n",
      "EPOCH 28/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5580 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5600 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5594 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5588 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5580 | Time: 3.2s\n",
      "\n",
      "Epoch 28 complete in 3.2s | Train Loss: 0.5580\n",
      "Test Loss: 0.5550 | Best: 0.5550 (Epoch 28)\n",
      "\n",
      "============================================================\n",
      "EPOCH 29/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5569 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5545 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5537 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5531 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5524 | Time: 3.3s\n",
      "\n",
      "Epoch 29 complete in 3.3s | Train Loss: 0.5524\n",
      "Test Loss: 0.5495 | Best: 0.5495 (Epoch 29)\n",
      "\n",
      "============================================================\n",
      "EPOCH 30/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5494 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5489 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5482 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5476 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5469 | Time: 3.2s\n",
      "\n",
      "Epoch 30 complete in 3.2s | Train Loss: 0.5469\n",
      "Test Loss: 0.5441 | Best: 0.5441 (Epoch 30)\n",
      "\n",
      "============================================================\n",
      "EPOCH 31/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5431 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5437 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5429 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5422 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5415 | Time: 3.3s\n",
      "\n",
      "Epoch 31 complete in 3.3s | Train Loss: 0.5415\n",
      "Test Loss: 0.5387 | Best: 0.5387 (Epoch 31)\n",
      "\n",
      "============================================================\n",
      "EPOCH 32/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5394 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5379 | Time: 0.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5375 | Time: 1.6s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5368 | Time: 2.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5361 | Time: 3.2s\n",
      "\n",
      "Epoch 32 complete in 3.2s | Train Loss: 0.5361\n",
      "Test Loss: 0.5333 | Best: 0.5333 (Epoch 32)\n",
      "\n",
      "============================================================\n",
      "EPOCH 33/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5343 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5328 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5321 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5315 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5308 | Time: 3.3s\n",
      "\n",
      "Epoch 33 complete in 3.3s | Train Loss: 0.5308\n",
      "Test Loss: 0.5280 | Best: 0.5280 (Epoch 33)\n",
      "\n",
      "============================================================\n",
      "EPOCH 34/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5298 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5280 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5271 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5263 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5256 | Time: 3.3s\n",
      "\n",
      "Epoch 34 complete in 3.3s | Train Loss: 0.5256\n",
      "Test Loss: 0.5228 | Best: 0.5228 (Epoch 34)\n",
      "\n",
      "============================================================\n",
      "EPOCH 35/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5223 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5222 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5217 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5210 | Time: 2.6s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5204 | Time: 3.4s\n",
      "\n",
      "Epoch 35 complete in 3.4s | Train Loss: 0.5204\n",
      "Test Loss: 0.5177 | Best: 0.5177 (Epoch 35)\n",
      "\n",
      "============================================================\n",
      "EPOCH 36/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5136 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5172 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5167 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5160 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5153 | Time: 3.4s\n",
      "\n",
      "Epoch 36 complete in 3.4s | Train Loss: 0.5153\n",
      "Test Loss: 0.5126 | Best: 0.5126 (Epoch 36)\n",
      "\n",
      "============================================================\n",
      "EPOCH 37/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5155 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5122 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5116 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5108 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5103 | Time: 3.8s\n",
      "\n",
      "Epoch 37 complete in 3.8s | Train Loss: 0.5103\n",
      "Test Loss: 0.5076 | Best: 0.5076 (Epoch 37)\n",
      "\n",
      "============================================================\n",
      "EPOCH 38/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5079 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5072 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5065 | Time: 2.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5059 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5053 | Time: 3.8s\n",
      "\n",
      "Epoch 38 complete in 3.8s | Train Loss: 0.5053\n",
      "Test Loss: 0.5026 | Best: 0.5026 (Epoch 38)\n",
      "\n",
      "============================================================\n",
      "EPOCH 39/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.5060 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.5021 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.5013 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.5009 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.5003 | Time: 3.8s\n",
      "\n",
      "Epoch 39 complete in 3.8s | Train Loss: 0.5003\n",
      "Test Loss: 0.4978 | Best: 0.4978 (Epoch 39)\n",
      "\n",
      "============================================================\n",
      "EPOCH 40/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4968 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4971 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4967 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4961 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4955 | Time: 3.7s\n",
      "\n",
      "Epoch 40 complete in 3.7s | Train Loss: 0.4955\n",
      "Test Loss: 0.4929 | Best: 0.4929 (Epoch 40)\n",
      "\n",
      "============================================================\n",
      "EPOCH 41/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4911 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4924 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4919 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4913 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4907 | Time: 3.8s\n",
      "\n",
      "Epoch 41 complete in 3.8s | Train Loss: 0.4907\n",
      "Test Loss: 0.4882 | Best: 0.4882 (Epoch 41)\n",
      "\n",
      "============================================================\n",
      "EPOCH 42/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4904 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4878 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4871 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4865 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4859 | Time: 3.7s\n",
      "\n",
      "Epoch 42 complete in 3.7s | Train Loss: 0.4859\n",
      "Test Loss: 0.4834 | Best: 0.4834 (Epoch 42)\n",
      "\n",
      "============================================================\n",
      "EPOCH 43/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4835 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4830 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4824 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4818 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4813 | Time: 3.9s\n",
      "\n",
      "Epoch 43 complete in 3.9s | Train Loss: 0.4813\n",
      "Test Loss: 0.4788 | Best: 0.4788 (Epoch 43)\n",
      "\n",
      "============================================================\n",
      "EPOCH 44/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4785 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4785 | Time: 1.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4778 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4773 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4766 | Time: 3.6s\n",
      "\n",
      "Epoch 44 complete in 3.6s | Train Loss: 0.4766\n",
      "Test Loss: 0.4742 | Best: 0.4742 (Epoch 44)\n",
      "\n",
      "============================================================\n",
      "EPOCH 45/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4768 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4734 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4731 | Time: 1.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4726 | Time: 2.5s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4721 | Time: 3.4s\n",
      "\n",
      "Epoch 45 complete in 3.4s | Train Loss: 0.4721\n",
      "Test Loss: 0.4697 | Best: 0.4697 (Epoch 45)\n",
      "\n",
      "============================================================\n",
      "EPOCH 46/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4700 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4695 | Time: 1.4s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4687 | Time: 2.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4682 | Time: 4.3s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4676 | Time: 5.6s\n",
      "\n",
      "Epoch 46 complete in 5.6s | Train Loss: 0.4676\n",
      "Test Loss: 0.4652 | Best: 0.4652 (Epoch 46)\n",
      "\n",
      "============================================================\n",
      "EPOCH 47/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4650 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4651 | Time: 1.2s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4645 | Time: 2.2s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4638 | Time: 3.6s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4632 | Time: 5.0s\n",
      "\n",
      "Epoch 47 complete in 5.0s | Train Loss: 0.4632\n",
      "Test Loss: 0.4608 | Best: 0.4608 (Epoch 47)\n",
      "\n",
      "============================================================\n",
      "EPOCH 48/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4621 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4606 | Time: 2.5s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4601 | Time: 4.2s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4595 | Time: 6.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4588 | Time: 8.2s\n",
      "\n",
      "Epoch 48 complete in 8.2s | Train Loss: 0.4588\n",
      "Test Loss: 0.4565 | Best: 0.4565 (Epoch 48)\n",
      "\n",
      "============================================================\n",
      "EPOCH 49/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4564 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4560 | Time: 1.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4556 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4549 | Time: 5.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4545 | Time: 7.0s\n",
      "\n",
      "Epoch 49 complete in 7.0s | Train Loss: 0.4545\n",
      "Test Loss: 0.4522 | Best: 0.4522 (Epoch 49)\n",
      "\n",
      "============================================================\n",
      "EPOCH 50/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4566 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4518 | Time: 1.7s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4511 | Time: 3.4s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4507 | Time: 5.6s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4502 | Time: 7.3s\n",
      "\n",
      "Epoch 50 complete in 7.3s | Train Loss: 0.4502\n",
      "Test Loss: 0.4480 | Best: 0.4480 (Epoch 50)\n",
      "\n",
      "============================================================\n",
      "EPOCH 51/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4535 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4476 | Time: 2.8s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4469 | Time: 4.7s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4465 | Time: 6.3s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4460 | Time: 7.5s\n",
      "\n",
      "Epoch 51 complete in 7.5s | Train Loss: 0.4460\n",
      "Test Loss: 0.4438 | Best: 0.4438 (Epoch 51)\n",
      "\n",
      "============================================================\n",
      "EPOCH 52/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4442 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4433 | Time: 2.3s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4428 | Time: 5.2s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4424 | Time: 6.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4419 | Time: 9.8s\n",
      "\n",
      "Epoch 52 complete in 9.8s | Train Loss: 0.4419\n",
      "Test Loss: 0.4397 | Best: 0.4397 (Epoch 52)\n",
      "\n",
      "============================================================\n",
      "EPOCH 53/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4400 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4391 | Time: 1.5s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4388 | Time: 3.3s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4384 | Time: 5.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4378 | Time: 7.2s\n",
      "\n",
      "Epoch 53 complete in 7.2s | Train Loss: 0.4378\n",
      "Test Loss: 0.4356 | Best: 0.4356 (Epoch 53)\n",
      "\n",
      "============================================================\n",
      "EPOCH 54/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4370 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4352 | Time: 1.5s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4347 | Time: 3.4s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4342 | Time: 5.4s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4338 | Time: 7.4s\n",
      "\n",
      "Epoch 54 complete in 7.4s | Train Loss: 0.4338\n",
      "Test Loss: 0.4316 | Best: 0.4316 (Epoch 54)\n",
      "\n",
      "============================================================\n",
      "EPOCH 55/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4307 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4313 | Time: 2.2s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4307 | Time: 4.2s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4303 | Time: 6.2s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4298 | Time: 8.1s\n",
      "\n",
      "Epoch 55 complete in 8.1s | Train Loss: 0.4298\n",
      "Test Loss: 0.4277 | Best: 0.4277 (Epoch 55)\n",
      "\n",
      "============================================================\n",
      "EPOCH 56/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4266 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4273 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4267 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4264 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4259 | Time: 8.0s\n",
      "\n",
      "Epoch 56 complete in 8.0s | Train Loss: 0.4259\n",
      "Test Loss: 0.4238 | Best: 0.4238 (Epoch 56)\n",
      "\n",
      "============================================================\n",
      "EPOCH 57/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4228 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4234 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4229 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4225 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4220 | Time: 7.9s\n",
      "\n",
      "Epoch 57 complete in 7.9s | Train Loss: 0.4220\n",
      "Test Loss: 0.4200 | Best: 0.4200 (Epoch 57)\n",
      "\n",
      "============================================================\n",
      "EPOCH 58/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4162 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4200 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4193 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4188 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4182 | Time: 7.9s\n",
      "\n",
      "Epoch 58 complete in 7.9s | Train Loss: 0.4182\n",
      "Test Loss: 0.4162 | Best: 0.4162 (Epoch 58)\n",
      "\n",
      "============================================================\n",
      "EPOCH 59/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4159 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4157 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4155 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4149 | Time: 5.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4145 | Time: 7.8s\n",
      "\n",
      "Epoch 59 complete in 7.8s | Train Loss: 0.4145\n",
      "Test Loss: 0.4125 | Best: 0.4125 (Epoch 59)\n",
      "\n",
      "============================================================\n",
      "EPOCH 60/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4105 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4120 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4117 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4111 | Time: 6.1s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4108 | Time: 8.1s\n",
      "\n",
      "Epoch 60 complete in 8.1s | Train Loss: 0.4108\n",
      "Test Loss: 0.4088 | Best: 0.4088 (Epoch 60)\n",
      "\n",
      "============================================================\n",
      "EPOCH 61/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4058 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4088 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4083 | Time: 4.2s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4076 | Time: 6.2s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4072 | Time: 8.2s\n",
      "\n",
      "Epoch 61 complete in 8.2s | Train Loss: 0.4072\n",
      "Test Loss: 0.4052 | Best: 0.4052 (Epoch 61)\n",
      "\n",
      "============================================================\n",
      "EPOCH 62/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4046 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4049 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4045 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4039 | Time: 6.1s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4036 | Time: 8.0s\n",
      "\n",
      "Epoch 62 complete in 8.0s | Train Loss: 0.4036\n",
      "Test Loss: 0.4017 | Best: 0.4017 (Epoch 62)\n",
      "\n",
      "============================================================\n",
      "EPOCH 63/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4017 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.4014 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.4009 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.4004 | Time: 5.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.4000 | Time: 7.9s\n",
      "\n",
      "Epoch 63 complete in 7.9s | Train Loss: 0.4000\n",
      "Test Loss: 0.3982 | Best: 0.3982 (Epoch 63)\n",
      "\n",
      "============================================================\n",
      "EPOCH 64/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.4017 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3977 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3974 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3969 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3966 | Time: 7.9s\n",
      "\n",
      "Epoch 64 complete in 7.9s | Train Loss: 0.3966\n",
      "Test Loss: 0.3947 | Best: 0.3947 (Epoch 64)\n",
      "\n",
      "============================================================\n",
      "EPOCH 65/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3955 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3947 | Time: 2.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3942 | Time: 3.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3937 | Time: 5.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3931 | Time: 7.5s\n",
      "\n",
      "Epoch 65 complete in 7.5s | Train Loss: 0.3931\n",
      "Test Loss: 0.3913 | Best: 0.3913 (Epoch 65)\n",
      "\n",
      "============================================================\n",
      "EPOCH 66/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3935 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3907 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3904 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3901 | Time: 6.1s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3898 | Time: 8.0s\n",
      "\n",
      "Epoch 66 complete in 8.0s | Train Loss: 0.3898\n",
      "Test Loss: 0.3880 | Best: 0.3880 (Epoch 66)\n",
      "\n",
      "============================================================\n",
      "EPOCH 67/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3915 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3875 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3872 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3868 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3864 | Time: 8.0s\n",
      "\n",
      "Epoch 67 complete in 8.0s | Train Loss: 0.3864\n",
      "Test Loss: 0.3847 | Best: 0.3847 (Epoch 67)\n",
      "\n",
      "============================================================\n",
      "EPOCH 68/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3855 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3847 | Time: 2.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3841 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3836 | Time: 6.1s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3832 | Time: 8.0s\n",
      "\n",
      "Epoch 68 complete in 8.0s | Train Loss: 0.3832\n",
      "Test Loss: 0.3815 | Best: 0.3815 (Epoch 68)\n",
      "\n",
      "============================================================\n",
      "EPOCH 69/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3801 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3811 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3806 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3802 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3800 | Time: 8.0s\n",
      "\n",
      "Epoch 69 complete in 8.0s | Train Loss: 0.3800\n",
      "Test Loss: 0.3783 | Best: 0.3783 (Epoch 69)\n",
      "\n",
      "============================================================\n",
      "EPOCH 70/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3782 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3778 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3777 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3773 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3768 | Time: 8.0s\n",
      "\n",
      "Epoch 70 complete in 8.0s | Train Loss: 0.3768\n",
      "Test Loss: 0.3751 | Best: 0.3751 (Epoch 70)\n",
      "\n",
      "============================================================\n",
      "EPOCH 71/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3723 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3746 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3744 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3740 | Time: 6.1s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3737 | Time: 8.1s\n",
      "\n",
      "Epoch 71 complete in 8.1s | Train Loss: 0.3737\n",
      "Test Loss: 0.3720 | Best: 0.3720 (Epoch 71)\n",
      "\n",
      "============================================================\n",
      "EPOCH 72/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3720 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3720 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3715 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3710 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3706 | Time: 8.0s\n",
      "\n",
      "Epoch 72 complete in 8.0s | Train Loss: 0.3706\n",
      "Test Loss: 0.3690 | Best: 0.3690 (Epoch 72)\n",
      "\n",
      "============================================================\n",
      "EPOCH 73/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3666 | Time: 0.2s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3689 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3684 | Time: 4.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3680 | Time: 6.0s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3676 | Time: 7.9s\n",
      "\n",
      "Epoch 73 complete in 7.9s | Train Loss: 0.3676\n",
      "Test Loss: 0.3660 | Best: 0.3660 (Epoch 73)\n",
      "\n",
      "============================================================\n",
      "EPOCH 74/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3657 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3657 | Time: 2.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3655 | Time: 4.1s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3649 | Time: 5.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3646 | Time: 7.1s\n",
      "\n",
      "Epoch 74 complete in 7.1s | Train Loss: 0.3646\n",
      "Test Loss: 0.3630 | Best: 0.3630 (Epoch 74)\n",
      "\n",
      "============================================================\n",
      "EPOCH 75/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3585 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3628 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3624 | Time: 2.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3620 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3617 | Time: 3.8s\n",
      "\n",
      "Epoch 75 complete in 3.8s | Train Loss: 0.3617\n",
      "Test Loss: 0.3601 | Best: 0.3601 (Epoch 75)\n",
      "\n",
      "============================================================\n",
      "EPOCH 76/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3548 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3599 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3595 | Time: 2.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3592 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3588 | Time: 3.8s\n",
      "\n",
      "Epoch 76 complete in 3.8s | Train Loss: 0.3588\n",
      "Test Loss: 0.3573 | Best: 0.3573 (Epoch 76)\n",
      "\n",
      "============================================================\n",
      "EPOCH 77/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3547 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3570 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3567 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3563 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3559 | Time: 3.7s\n",
      "\n",
      "Epoch 77 complete in 3.7s | Train Loss: 0.3559\n",
      "Test Loss: 0.3545 | Best: 0.3545 (Epoch 77)\n",
      "\n",
      "============================================================\n",
      "EPOCH 78/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3559 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3542 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3539 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3535 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3532 | Time: 3.6s\n",
      "\n",
      "Epoch 78 complete in 3.6s | Train Loss: 0.3532\n",
      "Test Loss: 0.3517 | Best: 0.3517 (Epoch 78)\n",
      "\n",
      "============================================================\n",
      "EPOCH 79/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3502 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3517 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3513 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3508 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3504 | Time: 3.6s\n",
      "\n",
      "Epoch 79 complete in 3.6s | Train Loss: 0.3504\n",
      "Test Loss: 0.3490 | Best: 0.3490 (Epoch 79)\n",
      "\n",
      "============================================================\n",
      "EPOCH 80/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3481 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3487 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3483 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3480 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3477 | Time: 3.5s\n",
      "\n",
      "Epoch 80 complete in 3.5s | Train Loss: 0.3477\n",
      "Test Loss: 0.3463 | Best: 0.3463 (Epoch 80)\n",
      "\n",
      "============================================================\n",
      "EPOCH 81/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3473 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3457 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3455 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3453 | Time: 2.6s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3450 | Time: 3.5s\n",
      "\n",
      "Epoch 81 complete in 3.5s | Train Loss: 0.3450\n",
      "Test Loss: 0.3437 | Best: 0.3437 (Epoch 81)\n",
      "\n",
      "============================================================\n",
      "EPOCH 82/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3439 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3434 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3430 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3428 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3424 | Time: 3.7s\n",
      "\n",
      "Epoch 82 complete in 3.7s | Train Loss: 0.3424\n",
      "Test Loss: 0.3411 | Best: 0.3411 (Epoch 82)\n",
      "\n",
      "============================================================\n",
      "EPOCH 83/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3390 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3407 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3404 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3401 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3399 | Time: 3.7s\n",
      "\n",
      "Epoch 83 complete in 3.7s | Train Loss: 0.3399\n",
      "Test Loss: 0.3386 | Best: 0.3386 (Epoch 83)\n",
      "\n",
      "============================================================\n",
      "EPOCH 84/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3383 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3379 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3378 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3377 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3373 | Time: 3.6s\n",
      "\n",
      "Epoch 84 complete in 3.6s | Train Loss: 0.3373\n",
      "Test Loss: 0.3361 | Best: 0.3361 (Epoch 84)\n",
      "\n",
      "============================================================\n",
      "EPOCH 85/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3363 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3361 | Time: 1.1s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3356 | Time: 2.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3353 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3349 | Time: 3.8s\n",
      "\n",
      "Epoch 85 complete in 3.8s | Train Loss: 0.3349\n",
      "Test Loss: 0.3336 | Best: 0.3336 (Epoch 85)\n",
      "\n",
      "============================================================\n",
      "EPOCH 86/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3333 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3335 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3331 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3327 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3324 | Time: 3.6s\n",
      "\n",
      "Epoch 86 complete in 3.6s | Train Loss: 0.3324\n",
      "Test Loss: 0.3312 | Best: 0.3312 (Epoch 86)\n",
      "\n",
      "============================================================\n",
      "EPOCH 87/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3356 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3307 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3305 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3304 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3300 | Time: 3.5s\n",
      "\n",
      "Epoch 87 complete in 3.5s | Train Loss: 0.3300\n",
      "Test Loss: 0.3288 | Best: 0.3288 (Epoch 87)\n",
      "\n",
      "============================================================\n",
      "EPOCH 88/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3273 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3288 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3282 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3279 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3277 | Time: 3.6s\n",
      "\n",
      "Epoch 88 complete in 3.6s | Train Loss: 0.3277\n",
      "Test Loss: 0.3265 | Best: 0.3265 (Epoch 88)\n",
      "\n",
      "============================================================\n",
      "EPOCH 89/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3294 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3263 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3259 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3255 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3254 | Time: 3.7s\n",
      "\n",
      "Epoch 89 complete in 3.7s | Train Loss: 0.3254\n",
      "Test Loss: 0.3242 | Best: 0.3242 (Epoch 89)\n",
      "\n",
      "============================================================\n",
      "EPOCH 90/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3266 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3239 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3235 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3234 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3231 | Time: 3.7s\n",
      "\n",
      "Epoch 90 complete in 3.7s | Train Loss: 0.3231\n",
      "Test Loss: 0.3219 | Best: 0.3219 (Epoch 90)\n",
      "\n",
      "============================================================\n",
      "EPOCH 91/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3194 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3213 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3215 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3211 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3208 | Time: 3.7s\n",
      "\n",
      "Epoch 91 complete in 3.7s | Train Loss: 0.3208\n",
      "Test Loss: 0.3197 | Best: 0.3197 (Epoch 91)\n",
      "\n",
      "============================================================\n",
      "EPOCH 92/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3196 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3197 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3191 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3188 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3186 | Time: 3.8s\n",
      "\n",
      "Epoch 92 complete in 3.8s | Train Loss: 0.3186\n",
      "Test Loss: 0.3176 | Best: 0.3176 (Epoch 92)\n",
      "\n",
      "============================================================\n",
      "EPOCH 93/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3146 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3171 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3171 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3166 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3165 | Time: 3.7s\n",
      "\n",
      "Epoch 93 complete in 3.7s | Train Loss: 0.3165\n",
      "Test Loss: 0.3154 | Best: 0.3154 (Epoch 93)\n",
      "\n",
      "============================================================\n",
      "EPOCH 94/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3199 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3152 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3150 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3146 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3144 | Time: 3.7s\n",
      "\n",
      "Epoch 94 complete in 3.7s | Train Loss: 0.3144\n",
      "Test Loss: 0.3133 | Best: 0.3133 (Epoch 94)\n",
      "\n",
      "============================================================\n",
      "EPOCH 95/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3123 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3131 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3126 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3126 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3123 | Time: 3.6s\n",
      "\n",
      "Epoch 95 complete in 3.6s | Train Loss: 0.3123\n",
      "Test Loss: 0.3113 | Best: 0.3113 (Epoch 95)\n",
      "\n",
      "============================================================\n",
      "EPOCH 96/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3110 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3111 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3109 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3105 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3102 | Time: 3.7s\n",
      "\n",
      "Epoch 96 complete in 3.7s | Train Loss: 0.3102\n",
      "Test Loss: 0.3092 | Best: 0.3092 (Epoch 96)\n",
      "\n",
      "============================================================\n",
      "EPOCH 97/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3101 | Time: 0.1s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3090 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3090 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3085 | Time: 2.7s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3082 | Time: 3.6s\n",
      "\n",
      "Epoch 97 complete in 3.6s | Train Loss: 0.3082\n",
      "Test Loss: 0.3073 | Best: 0.3073 (Epoch 97)\n",
      "\n",
      "============================================================\n",
      "EPOCH 98/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3024 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3067 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3066 | Time: 2.0s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3063 | Time: 2.9s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3063 | Time: 3.8s\n",
      "\n",
      "Epoch 98 complete in 3.8s | Train Loss: 0.3063\n",
      "Test Loss: 0.3053 | Best: 0.3053 (Epoch 98)\n",
      "\n",
      "============================================================\n",
      "EPOCH 99/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3101 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3047 | Time: 1.0s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3046 | Time: 1.9s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3046 | Time: 2.8s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3043 | Time: 3.7s\n",
      "\n",
      "Epoch 99 complete in 3.7s | Train Loss: 0.3043\n",
      "Test Loss: 0.3034 | Best: 0.3034 (Epoch 99)\n",
      "\n",
      "============================================================\n",
      "EPOCH 100/100\n",
      "============================================================\n",
      "  [  0.3%] Batch   0/337 | Loss: 0.3044 | Time: 0.0s\n",
      "  [ 25.2%] Batch  84/337 | Loss: 0.3030 | Time: 0.9s\n",
      "  [ 50.1%] Batch 168/337 | Loss: 0.3029 | Time: 1.8s\n",
      "  [ 75.1%] Batch 252/337 | Loss: 0.3026 | Time: 2.6s\n",
      "  [100.0%] Batch 336/337 | Loss: 0.3024 | Time: 3.4s\n",
      "\n",
      "Epoch 100 complete in 3.4s | Train Loss: 0.3024\n",
      "Test Loss: 0.3015 | Best: 0.3015 (Epoch 100)\n",
      "\n",
      "Training complete in 10.16 minutes.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training for {n_epochs} epochs...\\n\")\n",
    "\n",
    "# Track results\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "epoch_times = []\n",
    "best_test_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss, epoch_time = train_one_epoch(epoch)\n",
    "    test_loss = evaluate()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "    # Track best model\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        best_epoch = epoch\n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss': test_loss,\n",
    "        }, 'best_model.pt')\n",
    "        #print(f\"New best model saved! (Test Loss: {test_loss:.4f})\")\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f} | Best: {best_test_loss:.4f} (Epoch {best_epoch})\")\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"\\nTraining complete in {total_time/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca07703",
   "metadata": {},
   "source": [
    "Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc2e8c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Statistics:\n",
      "  Total epochs: 100\n",
      "  Total time: 10.2 minutes (609.7 seconds)\n",
      "  Average time per epoch: 4.7 seconds\n",
      "\n",
      "Loss Progression:\n",
      "  Initial train loss: 0.7343\n",
      "  Final train loss: 0.3024\n",
      "  Improvement: 58.8%\n",
      "\n",
      "Initial test loss: 0.7303\n",
      "  Final test loss: 0.3015\n",
      "  Best test loss: 0.3015 (Epoch 100)\n",
      "  Improvement: 58.7%\n",
      "\n",
      "Model saved as: best_model.pt\n",
      "\n",
      "Performance:\n",
      "  Training time: 10.2 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Statistics:\")\n",
    "print(f\"  Total epochs: {n_epochs}\")\n",
    "print(f\"  Total time: {total_time/60:.1f} minutes ({total_time:.1f} seconds)\")\n",
    "print(f\"  Average time per epoch: {np.mean(epoch_times):.1f} seconds\")\n",
    "print(f\"\\nLoss Progression:\")\n",
    "print(f\"  Initial train loss: {train_losses[0]:.4f}\")\n",
    "print(f\"  Final train loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"  Improvement: {(train_losses[0] - train_losses[-1])/train_losses[0]*100:.1f}%\")\n",
    "print(f\"\\nInitial test loss: {test_losses[0]:.4f}\")\n",
    "print(f\"  Final test loss: {test_losses[-1]:.4f}\")\n",
    "print(f\"  Best test loss: {best_test_loss:.4f} (Epoch {best_epoch})\")\n",
    "print(f\"  Improvement: {(test_losses[0] - best_test_loss)/test_losses[0]*100:.1f}%\")\n",
    "print(f\"\\nModel saved as: best_model.pt\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Training time: {total_time/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ef76e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training curves saved as: training_results.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(1, n_epochs + 1)\n",
    "plt.plot(epochs_range, train_losses, 'b-o', label='Train Loss', linewidth=2, markersize=8)\n",
    "plt.plot(epochs_range, test_losses, 'r-s', label='Test Loss', linewidth=2, markersize=8)\n",
    "plt.axhline(y=best_test_loss, color='g', linestyle='--', label=f'Best Test ({best_test_loss:.4f})', linewidth=1)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Progress', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Time plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(epochs_range, epoch_times, color='steelblue', alpha=0.7)\n",
    "plt.axhline(y=np.mean(epoch_times), color='r', linestyle='--', label=f'Average ({np.mean(epoch_times):.1f}s)', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Time (seconds)', fontsize=12)\n",
    "plt.title('Time per Epoch', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\nTraining curves saved as: training_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf34710",
   "metadata": {},
   "source": [
    "Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40136c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete training history saved as: final_model_complete.pt\n",
      "\n",
      "This includes:\n",
      "  - Final model weights\n",
      "  - All loss curves\n",
      "  - Training times\n",
      "  - Configuration\n"
     ]
    }
   ],
   "source": [
    "# Save final model and training history\n",
    "torch.save({\n",
    "    'n_epochs': n_epochs,\n",
    "    'final_epoch': n_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'epoch_times': epoch_times,\n",
    "    'best_test_loss': best_test_loss,\n",
    "    'best_epoch': best_epoch,\n",
    "    'config': {\n",
    "        'n_qubits': n_qubits,\n",
    "        'n_layers': n_layers,\n",
    "        'latent_dim': latent_dim,\n",
    "        'img_size': img_size,\n",
    "        'batch_size': batch_size,\n",
    "    }\n",
    "}, 'final_model_complete.pt')\n",
    "\n",
    "print(\"\\nComplete training history saved as: final_model_complete.pt\")\n",
    "print(\"\\nThis includes:\")\n",
    "print(\"  - Final model weights\")\n",
    "print(\"  - All loss curves\")\n",
    "print(\"  - Training times\")\n",
    "print(\"  - Configuration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
