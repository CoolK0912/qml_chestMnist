{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6e1489",
   "metadata": {},
   "source": [
    "# Quantum-Classical Hybrid Autoencoder for Medical Image Classification\n",
    "\n",
    "This notebook implements a hybrid quantum-classical model for chest X-ray classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-deps",
   "metadata": {},
   "source": [
    "## Installation (Run if packages missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if you need to install packages\n",
    "# %pip install torch torchvision numpy pennylane medmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89333376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.8.0+cpu\n",
      "PennyLane version: 0.42.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pennylane as qml\n",
    "from pennylane.qnn import TorchLayer\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PennyLane version: {qml.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a80afb",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01a2bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Qubits: 6\n",
      "  Quantum layers: 2\n",
      "  Latent dimension: 64\n",
      "  Image size: 224x224\n",
      "  Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 6                 # set desired number of qubits\n",
    "n_layers = 2                 # set desired number of quantum layers\n",
    "latent_dim = 2**n_qubits     # latent dimension = 2^n_qubits\n",
    "img_size = 224               # set desired image size (28, 64, 128, 224)\n",
    "batch_size = 32\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Qubits: {n_qubits}\")\n",
    "print(f\"  Quantum layers: {n_layers}\")\n",
    "print(f\"  Latent dimension: {latent_dim}\")\n",
    "print(f\"  Image size: {img_size}x{img_size}\")\n",
    "print(f\"  Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74359e0",
   "metadata": {},
   "source": [
    "## Load Data from preprocess.py\n",
    "\n",
    "We import the data loaders from our preprocess.py file to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e8e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Training samples: 78468\n",
      "Test samples: 22433\n",
      "Training batches: 2452\n",
      "Test batches: 702\n"
     ]
    }
   ],
   "source": [
    "# Import data loaders from preprocess.py\n",
    "from preprocess import train_loader, test_loader, train_dataset, test_dataset\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd582d",
   "metadata": {},
   "source": [
    "Filter Out Double-Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fc1bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering for single-label images only...\n",
      "✓ Filtered Training: 21602 single-label images (675 batches)\n",
      "✓ Filtered Test: 6259 single-label images (196 batches)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "print(\"Filtering for single-label images only...\")\n",
    "\n",
    "# Filter training set\n",
    "train_single_label_indices = []\n",
    "for i in range(len(train_dataset)):\n",
    "    _, label = train_dataset[i]\n",
    "    if label.sum() == 1:  # Only one condition present\n",
    "        train_single_label_indices.append(i)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_single_label_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "# Filter test set\n",
    "test_single_label_indices = []\n",
    "for i in range(len(test_dataset)):\n",
    "    _, label = test_dataset[i]\n",
    "    if label.sum() == 1:\n",
    "        test_single_label_indices.append(i)\n",
    "\n",
    "test_dataset = Subset(test_dataset, test_single_label_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "print(f\"✓ Filtered Training: {len(train_dataset)} single-label images ({len(train_loader)} batches)\")\n",
    "print(f\"✓ Filtered Test: {len(test_dataset)} single-label images ({len(test_loader)} batches)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf487ff",
   "metadata": {},
   "source": [
    "## Classical Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cc5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64, img_size=224):\n",
    "        super().__init__()\n",
    "        self.h8 = img_size // 8\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Initialize encoder weights properly\n",
    "        for m in self.encoder.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)  # (B,latent_dim)\n",
    "        return z  # Return unnormalized z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4a989",
   "metadata": {},
   "source": [
    "## Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e4fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum device initialized: <default.qubit device (wires=6) at 0x29f00215410>\n",
      "QuantumHead with EXTREME safety checks!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---- quantum device ----\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def qnode(inputs, weights):\n",
    "    # inputs: shape (2**n_qubits,), NOT batched - single sample\n",
    "    qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True, pad_with=0.0)\n",
    "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class QuantumHead(nn.Module):\n",
    "    def __init__(self, n_layers, n_qubits, n_classes, latent_dim):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.encoder_fc = nn.Linear(latent_dim, 2**n_qubits)\n",
    "        \n",
    "        # Better weight initialization\n",
    "        nn.init.xavier_uniform_(self.encoder_fc.weight, gain=0.01)  # Even smaller gain\n",
    "        nn.init.zeros_(self.encoder_fc.bias)\n",
    "        \n",
    "        # Initialize quantum weights manually\n",
    "        self.q_weights = nn.Parameter(torch.randn(n_layers, n_qubits, 3) * 0.001)  # Very small initialization\n",
    "        \n",
    "        # Readout layer\n",
    "        self.readout = nn.Linear(n_qubits, n_classes)\n",
    "\n",
    "    def forward(self, h):\n",
    "        # h: (B, latent_dim)\n",
    "        batch_size = h.shape[0]\n",
    "        \n",
    "        # Check input for NaN\n",
    "        if torch.isnan(h).any() or torch.isinf(h).any():\n",
    "            print(\"⚠️ NaN/Inf in input h!\")\n",
    "            h = torch.nan_to_num(h, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        z = self.encoder_fc(h)  # (B, 2**n_qubits)\n",
    "        \n",
    "        # Aggressive NaN/Inf replacement\n",
    "        z = torch.nan_to_num(z, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        # Clamp BEFORE normalization\n",
    "        z = torch.clamp(z, min=-5, max=5)\n",
    "        \n",
    "        # Normalize per row with extreme safety\n",
    "        norm = torch.sqrt(torch.sum(z**2, dim=1, keepdim=True) + 1e-10)\n",
    "        \n",
    "        # If norm is too small, replace entire row with uniform vector\n",
    "        small_norm_mask = norm.squeeze() < 1e-6\n",
    "        if small_norm_mask.any():\n",
    "            print(f\"⚠️ {small_norm_mask.sum().item()} rows with near-zero norm, fixing...\")\n",
    "            uniform_vec = torch.ones(2**self.n_qubits, device=z.device) / np.sqrt(2**self.n_qubits)\n",
    "            z[small_norm_mask] = uniform_vec\n",
    "            norm = torch.sqrt(torch.sum(z**2, dim=1, keepdim=True) + 1e-10)\n",
    "        \n",
    "        z_normalized = z / norm\n",
    "        \n",
    "        # Final verification\n",
    "        z_normalized = torch.nan_to_num(z_normalized, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        # Re-normalize after NaN replacement\n",
    "        final_norm = torch.sqrt(torch.sum(z_normalized**2, dim=1, keepdim=True) + 1e-10)\n",
    "        z_normalized = z_normalized / final_norm\n",
    "        \n",
    "        # Manual batching - process one sample at a time\n",
    "        results = []\n",
    "        for i in range(batch_size):\n",
    "            single_input = z_normalized[i].detach().clone()\n",
    "            \n",
    "            # Triple check this specific sample\n",
    "            if torch.isnan(single_input).any() or torch.isinf(single_input).any():\n",
    "                print(f\"⚠️ Sample {i} still has NaN/Inf! Using uniform vector.\")\n",
    "                single_input = torch.ones(2**self.n_qubits, device=z.device) / np.sqrt(2**self.n_qubits)\n",
    "            \n",
    "            # Verify norm is close to 1\n",
    "            sample_norm = torch.sqrt(torch.sum(single_input**2))\n",
    "            if abs(sample_norm - 1.0) > 0.1:\n",
    "                print(f\"⚠️ Sample {i} norm is {sample_norm.item():.4f}, renormalizing...\")\n",
    "                single_input = single_input / (sample_norm + 1e-10)\n",
    "            \n",
    "            try:\n",
    "                # Run quantum circuit on single sample\n",
    "                expvals = qnode(single_input, self.q_weights)\n",
    "                expvals_tensor = torch.stack(expvals).float()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Quantum circuit failed for sample {i}: {e}\")\n",
    "                # Return zeros if circuit fails\n",
    "                expvals_tensor = torch.zeros(self.n_qubits, device=z.device)\n",
    "            \n",
    "            results.append(expvals_tensor)\n",
    "        \n",
    "        # Stack all results back into batch\n",
    "        expvals_batch = torch.stack(results)  # (B, n_qubits)\n",
    "        \n",
    "        # Final readout layer\n",
    "        return self.readout(expvals_batch)\n",
    "\n",
    "print(f\"Quantum device initialized: {dev}\")\n",
    "print(\"QuantumHead with EXTREME safety checks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb7783",
   "metadata": {},
   "source": [
    "## Hybrid Quantum-Classical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa6eb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridQML(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, n_classes=14):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(latent_dim=latent_dim, img_size=img_size)\n",
    "        self.qhead = QuantumHead(n_layers=n_layers, n_qubits=n_qubits, n_classes=n_classes, latent_dim=latent_dim)\n",
    "\n",
    "    def forward(self, x, return_recon=False):\n",
    "        h = self.enc(x)\n",
    "        out = self.qhead(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051572bf",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a244a507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "✓ Model recreated with dtype fix!\n",
      "Parameters: 105,222\n",
      "Training functions defined successfully!\n",
      "Model has 105222 parameters\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = HybridQML(img_size=img_size, latent_dim=latent_dim, n_classes=14).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=5e-5,\n",
    "    weight_decay=1e-5,\n",
    "    eps=1e-7\n",
    ")\n",
    "\n",
    "clf_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\"✓ Model recreated with dtype fix!\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    \n",
    "    for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        logits = model(imgs, return_recon=True)\n",
    "        loss = clf_criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # GRADIENT CLIPPING - prevents NaN!\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item() * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"  Batch {batch_idx}/{len(train_loader)}, Avg Loss: {total/n:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch}: train loss = {total/n:.4f}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        logits = model(imgs)\n",
    "        loss = clf_criterion(logits, labels)\n",
    "        total += loss.item() * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "    print(f\"Test BCEWithLogits loss = {total/n:.4f}\")\n",
    "\n",
    "print(\"Training functions defined successfully!\")\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28252c5d",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd7e3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "  Batch 0/675, Avg Loss: 0.7675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     evaluate()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[1;32mIn[16], line 30\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m clf_criterion(logits, labels)\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# GRADIENT CLIPPING - prevents NaN!\u001b[39;00m\n\u001b[0;32m     33\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\function.py:311\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n\u001b[0;32m    310\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:101\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_backward\u001b[1;34m(ctx, *flat_grad_outputs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_backward\u001b[39m(ctx, \u001b[38;5;241m*\u001b[39mflat_grad_outputs):\n\u001b[0;32m    100\u001b[0m     grad_outputs \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_grad_outputs, ctx\u001b[38;5;241m.\u001b[39m_out_struct)\n\u001b[1;32m--> 101\u001b[0m     grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[43morig_bw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# None corresponds to the diff of out_struct_holder\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(grad_inputs)\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:190\u001b[0m, in \u001b[0;36mExecuteTapes.backward\u001b[1;34m(ctx, *dy)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Torch obeys the dL/dz_conj convention instead of the\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# dL/dz convention of PennyLane, autograd and jax. This converts between the formats\u001b[39;00m\n\u001b[0;32m    189\u001b[0m dy \u001b[38;5;241m=\u001b[39m _recursive_conj(dy)\n\u001b[1;32m--> 190\u001b[0m vjps \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# split tensor into separate entries\u001b[39;00m\n\u001b[0;32m    192\u001b[0m unpacked_vjps \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\jacobian_products.py:331\u001b[0m, in \u001b[0;36mTransformJacobianProducts.compute_vjp\u001b[1;34m(self, tapes, dy)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_vjps(jacs, dy, tapes)\n\u001b[0;32m    327\u001b[0m vjp_tapes, processing_fn \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mgradients\u001b[38;5;241m.\u001b[39mbatch_vjp(\n\u001b[0;32m    328\u001b[0m     tapes, dy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_transform, gradient_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_kwargs\n\u001b[0;32m    329\u001b[0m )\n\u001b[1;32m--> 331\u001b[0m vjp_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvjp_tapes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(processing_fn(vjp_results))\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\run.py:253\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_execute\u001b[39m(tapes: QuantumScriptBatch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultBatch:\n\u001b[0;32m    245\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execution that occurs within a ML framework boundary.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    Closure Variables:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m        device (qml.devices.Device): a Pennylane device\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m     transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m \u001b[43minner_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[0;32m    256\u001b[0m         results \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mexecute(transformed_tapes, execution_config\u001b[38;5;241m=\u001b[39mexecution_config)\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\transforms\\core\\transform_program.py:501\u001b[0m, in \u001b[0;36mTransformProgram.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaxpr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_jaxpr(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_tapes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\transforms\\core\\transform_program.py:431\u001b[0m, in \u001b[0;36mTransformProgram.__call_tapes\u001b[1;34m(self, tapes)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argnums \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unsubscriptable-object\u001b[39;00m\n\u001b[0;32m    430\u001b[0m     tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m argnums[tape_idx]\n\u001b[1;32m--> 431\u001b[0m new_tapes, fn \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m execution_tapes\u001b[38;5;241m.\u001b[39mextend(new_tapes)\n\u001b[0;32m    434\u001b[0m fns\u001b[38;5;241m.\u001b[39mappend(fn)\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:84\u001b[0m, in \u001b[0;36mconvert_to_numpy_parameters\u001b[1;34m(tape)\u001b[0m\n\u001b[0;32m     82\u001b[0m new_ops \u001b[38;5;241m=\u001b[39m (_convert_op_to_numpy_data(op) \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m     83\u001b[0m new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[1;32m---> 84\u001b[0m new_circuit \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_measurements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_params\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnull_postprocessing\u001b[39m(results):\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A postprocesing function returned by a transform that only converts the batch of results\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    into a result for a single ``QuantumTape``.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\tape\\qscript.py:194\u001b[0m, in \u001b[0;36mQuantumScript.__init__\u001b[1;34m(self, ops, measurements, shots, trainable_params)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    189\u001b[0m     ops: Optional[Iterable[Operator]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m     trainable_params: Optional[Sequence[\u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    193\u001b[0m ):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ops \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m ops \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(ops)\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_measurements \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m measurements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(measurements)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shots \u001b[38;5;241m=\u001b[39m Shots(shots)\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:82\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;129m@transform\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_numpy_parameters\u001b[39m(tape: QuantumScript) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[QuantumScriptBatch, PostprocessingFn]:\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transforms a circuit to one with purely numpy parameters.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     new_ops \u001b[38;5;241m=\u001b[39m (\u001b[43m_convert_op_to_numpy_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m     83\u001b[0m     new_measurements \u001b[38;5;241m=\u001b[39m (_convert_measurement_to_numpy_data(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[0;32m     84\u001b[0m     new_circuit \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[0;32m     85\u001b[0m         new_ops, new_measurements, shots\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mshots, trainable_params\u001b[38;5;241m=\u001b[39mtape\u001b[38;5;241m.\u001b[39mtrainable_params\n\u001b[0;32m     86\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\transforms\\convert_to_numpy_parameters.py:30\u001b[0m, in \u001b[0;36m_convert_op_to_numpy_data\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Use operator method to change parameters when it become available\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mbind_new_parameters(op, \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\math\\multi_dispatch.py:814\u001b[0m, in \u001b[0;36munwrap\u001b[1;34m(values, max_depth)\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_val, ndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01melse\u001b[39;00m new_val\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(values)(convert(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m values)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    816\u001b[0m     np\u001b[38;5;241m.\u001b[39mto_numpy(values, max_depth\u001b[38;5;241m=\u001b[39mmax_depth)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ArrayBox)\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mto_numpy(values)\n\u001b[0;32m    819\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\math\\multi_dispatch.py:814\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_val, ndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01melse\u001b[39;00m new_val\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(values)(\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m values)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    816\u001b[0m     np\u001b[38;5;241m.\u001b[39mto_numpy(values, max_depth\u001b[38;5;241m=\u001b[39mmax_depth)\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ArrayBox)\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mto_numpy(values)\n\u001b[0;32m    819\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\math\\multi_dispatch.py:809\u001b[0m, in \u001b[0;36munwrap.<locals>.convert\u001b[1;34m(val)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unwrap(val)\n\u001b[0;32m    808\u001b[0m new_val \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 809\u001b[0m     np\u001b[38;5;241m.\u001b[39mto_numpy(val, max_depth\u001b[38;5;241m=\u001b[39mmax_depth) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, ArrayBox) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m )\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_val, ndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_val\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01melse\u001b[39;00m new_val\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autoray\\autoray.py:81\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m backend \u001b[38;5;241m=\u001b[39m _choose_backend(fn, args, kwargs, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[0;32m     80\u001b[0m func \u001b[38;5;241m=\u001b[39m get_lib_fn(backend, fn)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sreev\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\math\\single_dispatch.py:617\u001b[0m, in \u001b[0;36m_to_numpy_torch\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_conj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mis_conj():  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;66;03m# The following line is only covered if using Torch <v1.10.0\u001b[39;00m\n\u001b[0;32m    615\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mresolve_conj()\n\u001b[1;32m--> 617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    train_one_epoch(epoch)\n",
    "    evaluate()\n",
    "    print()\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
